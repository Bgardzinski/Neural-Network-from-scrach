{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class NN:\n",
    "    \n",
    "    def __init__(self, nlayers, actv_func, last_actv_func):\n",
    "        self.weights = []\n",
    "        self.outputs = []\n",
    "        self.activations = [self.sigmoid][actv_func]\n",
    "        self.gradient = [self.sigmoid_grad, self.sigmoid_grad]\n",
    "        self.final = 0\n",
    "        self.nb_layers = int(len(nlayers))\n",
    "        for i in range(len(nlayers)-1):   #niepotrzebny jest ten loop\n",
    "            self.weights.append((np.random.rand(nlayers[i],nlayers[i+1])-0.5)*2)\n",
    "            self.outputs.append(np.zeros(nlayers[i]))\n",
    "        self.outputs.append(np.zeros(nlayers[self.nb_layers-1]))\n",
    "                 \n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    \n",
    "    def softmax_grad(self, softmax):\n",
    "    # function and explanation from https://stackoverflow.com/questions/54976533/derivative-of-softmax-function-in-python\n",
    "        s = softmax.reshape(-1,1)\n",
    "        return np.diagflat(s) - np.dot(s, s.T)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_grad(self, x):\n",
    "        return (self.sigmoid(x) * (1 - self.sigmoid(x)))\n",
    "\n",
    "    def relu(self, a):\n",
    "        return np.array(list(map(lambda d: max(0,d),a)))\n",
    "    \n",
    "    def relu_grad(self,a):\n",
    "        return (a > 0) * 1\n",
    "            \n",
    "    def calc_output(self, iput):\n",
    "        y_prev = iput\n",
    "        self.outputs[0] = np.array(iput)\n",
    "        if len(iput) != self.weights[0].shape[0]:\n",
    "            print('Not enough or too much inputs!')\n",
    "        else:\n",
    "            for i in range(1,self.nb_layers):\n",
    "                self.outputs[i] = np.matmul(np.transpose(self.weights[i-1]),y_prev.reshape(-1, 1))\n",
    "                y_prev = self.activations(self.outputs[i])\n",
    "        #self.final = self.softmax(self.outputs[self.nb_layers-1])\n",
    "        self.final = self.sigmoid(self.outputs[self.nb_layers-1])\n",
    "        \n",
    "    def learn(self, factor, iterations, inputs, expected_outputs):\n",
    "        for _ in range(iterations):\n",
    "            c = list(zip(inputs.copy(), expected_outputs.copy()))\n",
    "            random.shuffle(c)\n",
    "            for i,j in c:\n",
    "                self.calc_output(i)\n",
    "                errors = j.reshape(-1, 1) - self.final\n",
    "                for k in range(1,self.nb_layers):           #backpropagation https://stats.stackexchange.com/questions/267576/matrix-representation-of-softmax-derivatives-in-backpropagation\n",
    "                    if (k==1):\n",
    "                        #d = np.matmul((self.gradient[(k>1)*1](self.outputs[-k])),errors)\n",
    "                        d = errors * (self.gradient[(k>1)*1](self.outputs[-k]).reshape(-1, 1))\n",
    "                    else:\n",
    "                        d = errors * (self.gradient[(k>1)*1](self.outputs[-k]).reshape(-1, 1))\n",
    "                    dW = np.matmul((self.sigmoid(self.outputs[-(k+1)])).reshape(-1, 1),d.T)\n",
    "                    #print('dW')\n",
    "                    #print(dW)\n",
    "                    if k+1 != self.nb_layers:\n",
    "                        errors = np.matmul(self.weights[-k],d)\n",
    "                    self.weights[-k] = self.weights[-k] + (factor*dW)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = NN([4,5,6,3], 0,0)\n",
    "x.learn(0.01,1000,(data.data).copy(),(target).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(150):\n",
    "    x.calc_output(data.data[i])\n",
    "    print ((list(x.final)).index(max(x.final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "target = np.zeros((data.target.shape[0],3))\n",
    "for i in range(data.target.shape[0]):\n",
    "    target[i][data.target[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
